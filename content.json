{"meta":{"title":"拒绝再玩","subtitle":"","description":"","author":"duoyu","url":"http://yoursite.com","root":"/"},"pages":[],"posts":[{"title":"k8s进阶-架构-节点","slug":"k8s进阶-架构","date":"2020-03-26T02:21:12.000Z","updated":"2020-03-26T08:15:43.304Z","comments":true,"path":"2020/03/26/k8s进阶-架构/","link":"","permalink":"http://yoursite.com/2020/03/26/k8s%E8%BF%9B%E9%98%B6-%E6%9E%B6%E6%9E%84/","excerpt":"节点 节点管理","text":"节点 节点管理 节点节点状态节点的状态包含如下信息： Addresses Conditions Capacity and Allocatable Info 执行以下命令可查看所有节点的列表 1kubectl get nodes -o wide 执行以下命令可查看节点状态以及节点的其他详细信息： 1kubectl describe node &lt;your-node-name&gt; Addresses HostName： 在节点命令行界面上执行 hostname 命令所获得的值。启动 kubelet 时，可以通过参数 --hostname-override 覆盖 ExternalIP：通常是节点的外部IP（可以从集群外访问的内网IP地址；上面的例子中，此字段为空） InternalIP：通常是从节点内部可以访问的 IP 地址 ConditionsConditions 描述了节点的状态。Condition的例子有： Node Condition 描述 OutOfDisk 如果节点上的空白磁盘空间不够，不能够再添加新的节点时，该字段为 True，其他情况为 False Ready 如果节点是健康的且已经就绪可以接受新的 Pod。则节点Ready字段为 True。False表明了该节点不健康，不能够接受新的 Pod。 MemoryPressure 如果节点内存紧张，则该字段为 True，否则为False PIDPressure 如果节点上进程过多，则该字段为 True，否则为 False DiskPressure 如果节点磁盘空间紧张，则该字段为 True，否则为 False NetworkUnvailable 如果节点的网络配置有问题，则该字段为 True，否则为 False Capacity and Allocatable（容量和可分配量）容量和可分配量（Capacity and Allocatable）描述了节点上的可用资源的情况： CPU 内存 该节点可调度的最大 pod 数量 Capacity 中的字段表示节点上的资源总数，Allocatable 中的字段表示该节点上可分配给普通 Pod 的资源总数。 Info描述了节点的基本信息，例如： Linux 内核版本 Kubernetes 版本（kubelet 和 kube-proxy 的版本） Docker 版本 操作系统名称 这些信息由节点上的 kubelet 收集。 节点管理与 Pod 和 Service 不一样，节点并不是由 Kubernetes 创建的，节点由云供应商（例如，Google Compute Engine、阿里云等）创建，或者节点已经存在于您的物理机/虚拟机的资源池。向 Kubernetes 中创建节点时，仅仅是创建了一个描述该节点的 API 对象。节点 API 对象创建成功后，Kubernetes将检查该节点是否有效。 节点控制器（Node Controller）节点控制器是一个负责管理节点的 Kubernetes master 组件。在节点的生命周期中，节点控制器起到了许多作用。 节点控制器在注册节点时为节点分配 CIDR 地址块 节点控制器通过云供应商（cloud-controller-manager）接口检查节点列表中每一个节点对象对应的虚拟机是否可用。在云环境中，只要节点状态异常，节点控制器检查其虚拟机在云供应商的状态，如果虚拟机不可用，自动将节点对象从 APIServer 中删除。 节点控制器监控节点的健康状况。当节点变得不可触达时（例如，由于节点已停机，节点控制器不再收到来自节点的心跳信号），节点控制器将节点API对象的 NodeStatus Condition 取值从 NodeReady 更新为 Unknown；然后在等待 pod-eviction-timeout 时间后，将节点上的所有 Pod 从节点驱逐。 默认40秒未收到心跳，修改 NodeStatus Condition 为 Unknown； 默认 pod-eviction-timeout 为 5分钟 节点控制器每隔 --node-monitor-period 秒检查一次节点的状态 节点自注册（Self-Registration）如果 kubelet 的启动参数 --register-node为 true（默认为 true），kubelet 会尝试将自己注册到 API Server。kubelet自行注册时，将使用如下选项： --kubeconfig：向 apiserver 进行认证时所用身份信息的路径 --cloud-provider：向云供应商读取节点自身元数据 --register-node：自动向 API Server 注册节点 --register-with-taints：注册节点时，为节点添加污点（逗号分隔，格式为 =: --node-ip：节点的 IP 地址 --node-labels：注册节点时，为节点添加标签 --node-status-update-frequency：向 master 节点发送心跳信息的时间间隔 如果 Node authorization mode 和 NodeRestriction admission plugin 被启用，kubelet 只拥有创建/修改其自身所对应的节点 API 对象的权限。 手动管理节点如果想要手工创建节点API对象，可以将 kubelet 的启动参数 --register-node 设置为 false。 管理员可以修改节点API对象（不管是否设置了 --register-node 参数）。可以修改的内容有： 增加/减少标签 标记节点为不可调度（unschedulable） 节点的标签与 Pod 上的节点选择器（node selector）配合，可以控制调度方式，例如，限定 Pod 只能在某一组节点上运行。 执行如下命令可将节点标记为不可调度（unschedulable），此时将阻止新的 Pod 被调度到该节点上，但是不影响任何已经在该节点上运行的 Pod。这在准备重启节点之前非常有用。 1kubectl cordon $NODENAME 节点容量（Node Capacity）Kubernetes 调度器在调度 Pod 到节点上时，将确保节点上有足够的资源。具体来说，调度器检查节点上所有容器的资源请求之和不大于节点的容量。此时，只能检查由 kubelet 启动的容器，不包括直接由容器引擎启动的容器，更不包括不在容器里运行的进程","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://yoursite.com/categories/kubernetes/"}],"tags":[]},{"title":"伸缩服务和滚动更新","slug":"伸缩服务","date":"2020-03-25T08:43:30.000Z","updated":"2020-03-25T09:09:44.425Z","comments":true,"path":"2020/03/25/伸缩服务/","link":"","permalink":"http://yoursite.com/2020/03/25/%E4%BC%B8%E7%BC%A9%E6%9C%8D%E5%8A%A1/","excerpt":"通过更改部署中的 replicas（副本数）来完成伸缩","text":"通过更改部署中的 replicas（副本数）来完成伸缩 Scaling（伸缩）应用程序 伸缩 的实现可以通过更改 nginx-deployment.yaml 文件中部署的 replicas（副本数）来完成 12spec: replicas: 4 #使用该Deployment创建两个应用程序实例 修改了 Deployment 的 replicas 为 4 后，Kubernetes 又为该 Deployment 创建了 3 新的 Pod，这 4 个 Pod 有相同的标签。因此Service A通过标签选择器与新的 Pod建立了对应关系，将访问流量通过负载均衡在 4 个 Pod 之间进行转发。 将 nginx Deployment 扩容到 4 个副本修改 nginx-deployment.yaml 文件，将 replicas 修改为 4 123456789101112131415161718192021apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployment labels: app: nginxspec: replicas: 4 #通过更改部署中的 replicas（副本数）来完成扩展 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 执行命令： 1234kubectl apply -f nginx-deployment.yaml#查看结果watch kubectl get pods -o wide 滚动更新用户期望应用程序始终可用，为此开发者/运维者在更新应用程序时要分多次完成。在 Kubernetes 中，这是通过 Rolling Update 滚动更新完成的。Rolling Update滚动更新 通过使用新版本的 Pod 逐步替代旧版本的 Pod 来实现 Deployment 的更新，从而实现零停机。新的 Pod 将在具有可用资源的 Node（节点）上进行调度。 Kubernetes 更新多副本的 Deployment 的版本时，会逐步的创建新版本的 Pod，逐步的停止旧版本的 Pod，以便使应用一直处于可用状态。这个过程中，Service 能够监视 Pod 的状态，将流量始终转发到可用的 Pod 上。 滚动更新步骤1.原本 Service A 将流量负载均衡到 4 个旧版本的 Pod （当中的容器为 绿色）上 1.原本 Service A 将流量负载均衡到 4 个旧版本的 Pod （当中的容器为 绿色）上 2.更新完 Deployment 部署文件中的镜像版本后，master 节点选择了一个 worker 节点，并根据新的镜像版本创建 Pod（紫色容器）。新 Pod 拥有唯一的新的 IP。同时，master 节点选择一个旧版本的 Pod 将其移除。 此时，Service A 将新 Pod 纳入到负载均衡中，将旧Pod移除 同步骤2，再创建一个新的 Pod 替换一个原有的 Pod 如此 Rolling Update 滚动更新，直到所有旧版本 Pod 均移除，新版本 Pod 也达到 Deployment 部署文件中定义的副本数，则滚动更新完成 更新 nginx Deployment 修改 nginx-deployment.yaml 文件123456789101112131415161718192021apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployment labels: app: nginxspec: replicas: 4 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.8 #使用镜像nginx:1.8替换原来的nginx:1.7.9 ports: - containerPort: 80 执行命令 1234kubectl apply -f nginx-deployment.yaml#查看过程及结果，可观察到 pod 逐个被替换的过程。watch kubectl get pods -l app=nginx","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://yoursite.com/categories/kubernetes/"}],"tags":[]},{"title":"Service服务","slug":"Service服务","date":"2020-03-25T07:09:33.000Z","updated":"2020-03-25T08:29:26.546Z","comments":true,"path":"2020/03/25/Service服务/","link":"","permalink":"http://yoursite.com/2020/03/25/Service%E6%9C%8D%E5%8A%A1/","excerpt":"Kubernetes Service（服务）概述","text":"Kubernetes Service（服务）概述 Service（服务）概述Pod 有自己的生命周期。当 worker node（节点）故障时，节点上运行的 Pod（容器组）也会消失。然后，Deployment 可以通过创建新的 Pod（容器组）来动态地将群集调整回原来的状态，以使应用程序保持运行。 Service的作用：由于 Kubernetes 集群中每个 Pod（容器组）都有一个唯一的 IP 地址（即使是同一个 Node 上的不同 Pod），service 可以解决为前端系统屏蔽后端系统的 Pod（容器组）在销毁、创建过程中所带来的 IP 地址的变化。 Kubernetes 中的 Service（服务） 提供了这样的一个抽象层，它选择具备某些特征的 Pod（容器组）并为它们定义一个访问方式。Service（服务）使 Pod（容器组）之间的相互依赖解耦（原本从一个 Pod 中访问另外一个 Pod，需要知道对方的 IP 地址）。一个 Service（服务）选定哪些 Pod（容器组） 通常由 LabelSelector(标签选择器) 来决定。 在创建Service的时候，通过设置配置文件中的 spec.type 字段的值，可以以不同方式向外部暴露应用程序： ClusterIP（默认） 在群集中的内部IP上公布服务，这种方式的 Service（服务）只在集群内部可以访问到 NodePort 使用 NAT 在集群中每个的同一端口上公布服务。这种方式下，可以通过访问集群中任意节点+端口号的方式访问服务 :。此时 ClusterIP 的访问方式仍然可用。 LoadBalancer 在云环境中（需要云供应商可以支持）创建一个集群外部的负载均衡器，并为使用该负载均衡器的 IP 地址作为服务的访问地址。此时 ClusterIP 和 NodePort 的访问方式仍然可用。 Service是一个抽象层，它通过 LabelSelector 选择了一组 Pod（容器组），把这些 Pod 的指定端口公布到到集群外部，并支持负载均衡和服务发现。 公布 Pod 的端口以使其可访问 在多个 Pod 间实现负载均衡 使用 Label 和 LabelSelector 服务和标签 下图中有两个服务Service A(黄色虚线)和Service B(蓝色虚线) Service A 将请求转发到 IP 为 10.10.10.1 的Pod上， Service B 将请求转发到 IP 为 10.10.10.2、10.10.10.3、10.10.10.4 的Pod上。 Service 将外部请求路由到一组 Pod 中，它提供了一个抽象层，使得 Kubernetes 可以在不影响服务调用者的情况下，动态调度容器组 Service使用 Labels、LabelSelector (标签和选择器 匹配一组 Pod。Labels（标签）是附加到 Kubernetes 对象的键/值对，其用途有多种： 将 Kubernetes 对象（Node、Deployment、Pod、Service等）指派用于开发环境、测试环境或生产环境 嵌入版本标签，使用标签区别不同应用软件版本 使用标签对 Kubernetes 对象进行分类 Labels（标签）和 LabelSelector（标签选择器）之间的关联关系 Deployment B 含有 LabelSelector 为 app=B 通过此方式声明含有 app=B 标签的 Pod 与之关联 通过 Deployment B 创建的 Pod 包含标签为 app=B Service B 通过标签选择器 app=B 选择可以路由的 Pod Labels（标签）可以在创建 Kubernetes 对象时附加上去，也可以在创建之后再附加上去。任何时候都可以修改一个 Kubernetes 对象的 Labels（标签） nginx Deployment 创建一个 Service创建nginx的Deployment中定义了Labels，如下：1234metadata: #译名为元数据，即Deployment的一些基本属性和信息 name: nginx-deployment #Deployment的名称 labels: #标签，可以灵活定位一个或多个资源，其中key和value均可自定义，可以定义多组 app: nginx #为该Deployment设置key为app，value为nginx的标签 创建文件 nginx-service.yaml12345678910111213141516apiVersion: v1kind: Servicemetadata: name: nginx-service #Service 的名称 labels: #Service 自己的标签 app: nginx #为该 Service 设置 key 为 app，value 为 nginx 的标签spec: #这是关于该 Service 的定义，描述了 Service 如何选择 Pod，如何被访问 selector: #标签选择器 app: nginx #选择包含标签 app:nginx 的 Pod ports: - name: nginx-port #端口的名字 protocol: TCP #协议类型 TCP/UDP port: 80 #集群内的其他容器组可通过 80 端口访问 Service nodePort: 32600 #通过任意节点的 32600 端口访问 Service targetPort: 80 #将请求转发到匹配 Pod 的 80 端口 type: NodePort #Serive的类型，ClusterIP/NodePort/LoaderBalancer 执行命令 1234567kubectl apply -f nginx-service.yaml#检查执行结果kubectl get services -o wide #可查看到名称为 nginx-service 的服务。#访问服务curl &lt;任意节点的 IP&gt;:32600","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://yoursite.com/categories/kubernetes/"}],"tags":[]},{"title":"查看Pods/Nodes","slug":"查看Pods-Nodes","date":"2020-03-25T06:05:21.000Z","updated":"2020-03-25T06:21:04.946Z","comments":true,"path":"2020/03/25/查看Pods-Nodes/","link":"","permalink":"http://yoursite.com/2020/03/25/%E6%9F%A5%E7%9C%8BPods-Nodes/","excerpt":"了解 Pod 和 Node","text":"了解 Pod 和 Node Pod​ Pod中的容器共享 IP 地址和端口空间（同一 Pod 中的不同 container 端口不能相互冲突），始终位于同一位置并共同调度，并在同一节点上的共享上下文中运行。（同一个Pod内的容器可以localhost + 端口互相访问）。 ​ 当在 k8s 上创建 Deployment 时，会在集群上创建包含容器的 Pod (而不是直接创建容器)。每个Pod都与运行它的 worker 节点（Node）绑定，并保持在那里直到终止或被删除。如果节点（Node）发生故障，则会在群集中的其他可用节点（Node）上运行相同的 Pod（从同样的镜像创建 Container，使用同样的配置，IP 地址不同，Pod 名字不同）。 Pod（容器组）是 k8s 集群上的最基本的单元。 Pod 是一组容器（可包含一个或多个应用程序容器），以及共享存储（卷 Volumes）、IP 地址和有关如何运行容器的信息。 如果多个容器紧密耦合并且需要共享磁盘等资源，则应该被部署在同一个Pod（容器组）中 Node Pod（容器组）总是在 Node（节点） 上运行。 Node（节点）是 kubernetes 集群中的计算机，可以是虚拟机或物理机。 每个 Node（节点）都由 master 管理。 一个 Node（节点）可以有多个Pod（容器组），kubernetes master 会根据每个 Node（节点）上可用资源的情况，自动调度 Pod（容器组）到最佳的 Node（节点）上。 每个Node（节点）至少运行： Kubelet，负责 master 节点和 worker 节点之间通信的进程；管理 Pod（容器组）和 Pod（容器组）内运行的 Container（容器）。 容器运行环境（如Docker）负责下载镜像、创建和运行容器等。 相关命令操作kubectl get - 显示资源列表1234567891011121314151617# kubectl get 资源类型#获取类型为Deployment的资源列表kubectl get deployments#获取类型为Pod的资源列表kubectl get pods#获取类型为Node的资源列表kubectl get nodes# 查看所有名称空间的 Deploymentkubectl get deployments -Akubectl get deployments --all-namespaces# 查看 kube-system 名称空间的 Deploymentkubectl get deployments -n kube-system kubectl describe - 显示有关资源的详细信息1234567# kubectl describe 资源类型 资源名称#查看名称为nginx-XXXXXX的Pod的信息kubectl describe pod nginx-XXXXXX #查看名称为nginx的Deployment的信息kubectl describe deployment nginx kubectl logs - 查看pod中的容器的打印日志（和命令docker logs 类似）12# kubectl logs Pod名称kubectl logs -f nginx-pod-XXXXXXX kubectl exec - 在pod中的容器环境内执行命令(和命令docker exec 类似)1234# kubectl exec Pod名称 操作命令# 在名称为nginx-pod-xxxxxx的Pod中运行bashkubectl exec -it nginx-pod-xxxxxx /bin/bash","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://yoursite.com/categories/kubernetes/"}],"tags":[]},{"title":"k8s部署一个应用程序","slug":"k8s部署一个应用程序","date":"2020-03-25T05:49:00.000Z","updated":"2020-03-25T05:59:21.447Z","comments":true,"path":"2020/03/25/k8s部署一个应用程序/","link":"","permalink":"http://yoursite.com/2020/03/25/k8s%E9%83%A8%E7%BD%B2%E4%B8%80%E4%B8%AA%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F/","excerpt":"使用 kubectl 在 k8s 上部署第一个应用程序。","text":"使用 kubectl 在 k8s 上部署第一个应用程序。 Deployment概念​ 通过发布 Deployment，可以创建应用程序 (docker image) 的实例 (docker container)，这个实例会被包含在称为 Pod 的概念中，Pod 是 k8s 中最小可管理单元。 ​ 在 k8s 集群中发布 Deployment 后，Deployment 将指示 k8s 如何创建和更新应用程序的实例，master 节点将应用程序实例调度到集群中的具体的节点上。 ​ 创建应用程序实例后，Kubernetes Deployment Controller 会持续监控这些实例。如果运行实例的 worker 节点关机或被删除，则 Kubernetes Deployment Controller 将在群集中资源最优的另一个 worker 节点上重新创建一个新的实例。这提供了一种自我修复机制来解决机器故障或维护问题。 ​ 通过创建应用程序实例并确保它们在集群节点中的运行实例个数，Kubernetes Deployment 提供了一种完全不同的方式来管理应用程序。 Deployment 处于 master 节点上，通过发布 Deployment，master 节点会选择合适的 worker 节点创建 Container（即图中的正方体），Container 会被包含在 Pod （即蓝色圆圈）里。 部署 nginx Deployment创建文件 nginx-deployment.yaml12345678910111213141516171819apiVersion: apps/v1 #与k8s集群版本有关，使用 kubectl api-versions 即可查看当前集群支持的版本kind: Deployment #该配置的类型，我们使用的是 Deploymentmetadata: #译名为元数据，即 Deployment 的一些基本属性和信息 name: nginx-deployment #Deployment 的名称 labels: #标签，可以灵活定位一个或多个资源，其中key和value均可自定义，可以定义多组，目前不需要理解 app: nginx #为该Deployment设置key为app，value为nginx的标签spec: #这是关于该Deployment的描述，可以理解为你期待该Deployment在k8s中如何使用 replicas: 1 #使用该Deployment创建一个应用程序实例 selector: #标签选择器，与上面的标签共同作用，目前不需要理解 matchLabels: #选择包含标签app:nginx的资源 app: nginx template: #这是选择或创建的Pod的模板 metadata: #Pod的元数据 labels: #Pod的标签，上面的selector即选择包含标签app:nginx的Pod app: nginx spec: #期望Pod实现的功能（即在pod中部署） containers: #生成container，与docker中的container是同一种 - name: nginx #container的名称 image: nginx:1.7.9 #使用镜像nginx:1.7.9创建container，该container默认80端口可访问 应用 YAML 文件1kubectl apply -f nginx-deployment.yaml 查看部署结果12345# 查看 Deploymentkubectl get deployments# 查看 Podkubectl get pods","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://yoursite.com/categories/kubernetes/"}],"tags":[]},{"title":"kubectl 命令技巧大全","slug":"kubectl 命令技巧大全","date":"2020-03-20T03:13:20.000Z","updated":"2020-03-20T07:20:09.424Z","comments":true,"path":"2020/03/20/kubectl 命令技巧大全/","link":"","permalink":"http://yoursite.com/2020/03/20/kubectl%20%E5%91%BD%E4%BB%A4%E6%8A%80%E5%B7%A7%E5%A4%A7%E5%85%A8/","excerpt":"一些基本的kubernets操作命令","text":"一些基本的kubernets操作命令 kubectl 命令技巧大全Kubectl 自动补全12345yum install -y bash-completionsource &#x2F;usr&#x2F;share&#x2F;bash-completion&#x2F;bash_completionsource &lt;(kubectl completion bash) 创建对象Kubernetes 的清单文件可以使用 json 或 yaml 格式定义。可以以 .yaml、.yml、或者 .json 为扩展名。 1234567891011$ kubectl create -f .&#x2F;my-manifest.yaml # 创建资源$ kubectl create -f .&#x2F;my1.yaml -f .&#x2F;my2.yaml # 使用多个文件创建资源$ kubectl create -f .&#x2F;dir # 使用目录下的所有清单文件来创建资源$ kubectl create -f https:&#x2F;&#x2F;git.io&#x2F;vPieo # 使用 url 来创建资源$ kubectl run nginx --image&#x3D;nginx # 启动一个 nginx 实例$ kubectl explain pods,svc # 获取 pod 和 svc 的文档 显示和查找资源 列出所有 namespace 中的所有service 1$ kubectl get services 列出所有 namespace 中的所有 pod 1$ kubectl get pods --all-namespaces 列出所有 pod 并显示详细信息 1$ kubectl get pods -o wide 列出指定 deployment 1$ kubectl get deployment my-dep 列出该 namespace 中的所有 pod 包括未初始化的 1$ kubectl get pods --include-uninitialized 使用详细输出来描述命令 12345 $ kubectl describe nodes my-node $ kubectl describe pods my-pod $ kubectl get services --sort-by&#x3D;.metadata.name 根据重启次数排序列出 pod 1$ kubectl get pods --sort-by&#x3D;&#39;.status.containerStatuses[0].restartCount&#39; 获取所有具有 app=cassandra 的 pod 中的 version 标签 1$ kubectl get pods --selector&#x3D;app&#x3D;cassandra rc -o \\ jsonpath&#x3D;&#39;&#123;.items[*].metadata.labels.version&#125;&#39; 获取所有节点的 ExternalIP 1$ kubectl get nodes -o jsonpath&#x3D;&#39;&#123;.items[*].status.addresses[?(@.type&#x3D;&#x3D;&quot;ExternalIP&quot;)].address&#125;&#39; 列出属于某个 PC 的 Pod 的名字，“jq”命令用于转换复杂的 jsonpath，参考 https://stedolan.github.io/jq/ 123 $ sel&#x3D;$&#123;$(kubectl get rc my-rc --output&#x3D;json | jq -j &#39;.spec.selector | to_entries | .[] | &quot;\\(.key)&#x3D;\\(.value),&quot;&#39;)%?&#125; $ echo $(kubectl get pods --selector&#x3D;$sel --output&#x3D;jsonpath&#x3D;&#123;.items..metadata.name&#125;) 查看哪些节点已就绪 1$ JSONPATH&#x3D;&#39;&#123;range .items[*]&#125;&#123;@.metadata.name&#125;:&#123;range @.status.conditions[*]&#125;&#123;@.type&#125;&#x3D;&#123;@.status&#125;;&#123;end&#125;&#123;end&#125;&#39; \\ &amp;&amp; kubectl get nodes -o jsonpath&#x3D;&quot;$JSONPATH&quot; | grep &quot;Ready&#x3D;True&quot; 列出当前 Pod 中使用的 Secret 1$ kubectl get pods -o json | jq &#39;.items[].spec.containers[].env[]?.valueFrom.secretKeyRef.name&#39; | grep -v null | sort | uniq 更新资源滚动更新 pod frontend-v1 1$ kubectl rolling-update frontend-v1 -f frontend-v2.json 更新资源名称并更新镜像 1$ kubectl rolling-update frontend-v1 frontend-v2 --image&#x3D;image:v2 更新 frontend pod 中的镜像 1$ kubectl rolling-update frontend --image&#x3D;image:v2 退出已存在的进行中的滚动更新 1$ kubectl rolling-update frontend-v1 frontend-v2 --rollback 基于 stdin 输入的 JSON 替换 pod 1$ cat pod.json | kubectl replace -f - 强制替换，删除后重新创建资源。会导致服务中断。 1$ kubectl replace --force -f .&#x2F;pod.json 为 nginx RC 创建服务，启用本地 80 端口连接到容器上的 8000 端口 1$ kubectl expose rc nginx --port&#x3D;80 --target-port&#x3D;8000 更新单容器 pod 的镜像版本（tag）到 v4 1$ kubectl get pod mypod -o yaml | sed &#39;s&#x2F;\\(image: myimage\\):.*$&#x2F;\\1:v4&#x2F;&#39; | kubectl replace -f - 添加标签 1$ kubectl label pods my-pod new-label&#x3D;awesome 添加注解 1$ kubectl annotate pods my-pod icon-url&#x3D;http:&#x2F;&#x2F;goo.gl&#x2F;XXBTWq 自动扩展 deployment “foo” 1$ kubectl autoscale deployment foo --min&#x3D;2 --max&#x3D;10 删除资源# 删除 pod.json 文件中定义的类型和名称的 pod 1$ kubectl delete -f .&#x2F;pod.json 删除名为“baz”的 pod 和名为“foo”的 service 1$ kubectl delete pod,service baz foo 删除具有 name=myLabel 标签的 pod 和 serivce 1$ kubectl delete pods,services -l name&#x3D;myLabel 删除具有 name=myLabel 标签的 pod 和 service，包括尚未初始化的 1$ kubectl delete pods,services -l name&#x3D;myLabel --include-uninitialized 删除 my-ns namespace 下的所有 pod 和 serivce，包括尚未初始化的 1$ kubectl -n my-ns delete po,svc --all 与运行中的Pod交互# dump 输出 pod 的日志（stdout） 1$ kubectl logs my-pod dump 输出 pod 中容器的日志（stdout，pod 中有多个容器的情况下使用） 1$ kubectl logs my-pod -c my-container 流式输出 pod 的日志（stdout） 1$ kubectl logs -f my-pod 流式输出 pod 中容器的日志（stdout，pod 中有多个容器的情况下使用） 1$ kubectl logs -f my-pod -c my-container 交互式 shell 的方式运行 pod 1$ kubectl run -i --tty busybox --image&#x3D;busybox -- sh 连接到运行中的容器 1$ kubectl attach my-pod -i 转发 pod 中的 6000 端口到本地的 5000 端口 1$ kubectl port-forward my-pod 5000:6000 在已存在的容器中执行命令（只有一个容器的情况下） 1$ kubectl exec my-pod -- ls &#x2F; 在已存在的容器中执行命令（pod 中有多个容器的情况下） 1$ kubectl exec my-pod -c my-container -- ls &#x2F; 显示指定 pod 和容器的指标度量 1$ kubectl top pod POD_NAME --containers 与节点和集群交互# 标记 my-node 不可调度 1$ kubectl cordon my-node 清空 my-node 以待维护 1$ kubectl drain my-node 标记 my-node 可调度 1$ kubectl uncordon my-node 显示 my-node 的指标度量 1$ kubectl top node my-node 显示 master 和服务的地址 1$ kubectl cluster-info 将当前集群状态输出到 stdout 1$ kubectl cluster-info dump 将当前集群状态输出到 /path/to/cluster-state 1$ kubectl cluster-info dump --output-directory&#x3D;&#x2F;path&#x2F;to&#x2F;cluster-state 如果该键和影响的污点（taint）已存在，则使用指定的值替换 1$ kubectl taint nodes foo dedicated&#x3D;special-user:NoSchedule 资源类型 缩写别名 clusters componentstatuses cs configmaps cm daemonsets ds deployments deploy endpoints ep event ev horizontalpodautoscalers hpa ingresses ing jobs limitranges limits namespaces ns networkpolicies nodes no statefulsets persistentvolumeclaims pvc persistentvolumes pv pods po podsecuritypolicies psp podtemplates replicasets rs replicationcontrollers rc resourcequotas quota cronjob secrets serviceaccount sa services svc storageclasses kubectl get - 显示资源列表#获取类型为Deployment的资源列表 1kubectl get deployments #获取类型为Pod的资源列表 1kubectl get pods #获取类型为Node的资源列表 1kubectl get nodes 名称空间在命令后增加 -A 或 –all-namespaces 可查看所有名称空间中的对象，使用参数 -n 可查看指定名称空间的对象，例如 # 查看所有名称空间的 Deployment 12kubectl get deployments -A kubectl get deployments --all-namespaces 查看 kube-system 名称空间的 Deployment 1kubectl get deployments -n kube-system 检查 kubectl 是否知道集群地址及凭证 1$ kubectl config view 通过 kubectl cluster-info 命令获得这些服务列表： 12345[root@ebs ~]# kubectl cluster-info Kubernetes master is running at https:&#x2F;&#x2F;172.16.121.88:6443 KubeDNS is running at https:&#x2F;&#x2F;172.16.121.88:6443&#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;kube-system&#x2F;services&#x2F;kube-dns:dns&#x2F;proxy To further debug and diagnose cluster problems, use &#39;kubectl cluster-info dump&#39;.","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://yoursite.com/categories/kubernetes/"}],"tags":[]},{"title":"Kubernetes核心概念","slug":"Kubernetes核心概念","date":"2020-03-20T03:10:20.000Z","updated":"2020-03-25T09:26:08.403Z","comments":true,"path":"2020/03/20/Kubernetes核心概念/","link":"","permalink":"http://yoursite.com/2020/03/20/Kubernetes%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/","excerpt":"Cluster，Pod，Label， Replication Controller ，Service …","text":"Cluster，Pod，Label， Replication Controller ，Service … 什么是Kubernetes？Kubernetes（k8s）是自动化容器操作的开源平台，这些操作包括部署，调度和节点集群间扩展。如果你曾经用过Docker容器技术部署容器，那么可以将Docker看成Kubernetes内部使用的低级别组件。Kubernetes不仅仅支持Docker，还支持Rocket，这是另一种容器技术。 使用Kubernetes可以： 自动化容器的部署和复制 随时扩展或收缩容器规模 将容器组织成组，并且提供容器间的负载均衡 很容易地升级应用程序容器的新版本 提供容器弹性，如果容器失效就替换它，等等… 集群集群是一组节点，这些节点可以是物理服务器或者虚拟机，之上安装了Kubernetes平台。下图展示这样的集群。注意该图为了强调核心概念有所简化。这里可以看到一个典型的Kubernetes架构图。 上图可以看到如下组件，使用特别的图标表示Service和Label： PodContainer（容器） Labe （标签） Replication Controller（复制控制器） Service（服务） Node（节点） Kubernetes Master（Kubernetes主节点） PodPod（上图绿色方框）安排在节点上，包含一组容器和卷。同一个Pod里的容器共享同一个网络命名空间，可以使用localhost互相通信。Pod是短暂的，不是持续性实体。你可能会有这些问题： 如果Pod是短暂的，那么我怎么才能持久化容器数据使其能够跨重启而存在呢？ 是的，Kubernetes支持 卷 的概念，因此可以使用持久化的卷类型。 是否手动创建Pod，如果想要创建同一个容器的多份拷贝，需要一个个分别创建出来么？可以手动创建单个Pod，但是也可以使用Replication Controller使用Pod模板创建出多份拷贝，下文会详细介绍。 如果Pod是短暂的，那么重启时IP地址可能会改变，那么怎么才能从前端容器正确可靠地指向后台容器呢？这时可以使用Service，下文会详细介绍。 Label正如图所示，一些Pod有Label 。一个Label是attach到Pod的一对键/值对，用来传递用户定义的属性。比如，你可能创建了一个”tier”和“app”标签，通过Label（tier=frontend, app=myapp）来标记前端Pod容器，使用Label（tier=backend, app=myapp）标记后台Pod。然后可以使用 [Selectors] 选择带有特定Label的Pod，并且将Service或者Replication Controller应用到上面。 Replication Controller是否手动创建Pod，如果想要创建同一个容器的多份拷贝，需要一个个分别创建出来么，能否将Pods划到逻辑组里？ Replication Controller确保任意时间都有指定数量的Pod“副本”在运行。如果为某个Pod创建了Replication Controller并且指定3个副本，它会创建3个Pod，并且持续监控它们。如果某个Pod不响应，那么Replication Controller会替换它，保持总数为3.如下面的动画所示： 如果之前不响应的Pod恢复了，现在就有4个Pod了，那么Replication Controller会将其中一个终止保持总数为3。如果在运行中将副本总数改为5，Replication Controller会立刻启动2个新Pod，保证总数为5。还可以按照这样的方式缩小Pod，这个特性在执行滚动 [升级] 时很有用。 当创建Replication Controller时，需要指定两个东西： Pod模板：用来创建Pod副本的模板 Label：Replication Controller需要监控的Pod的标签。现在已经创建了Pod的一些副本，那么在这些副本上如何均衡负载呢？我们需要的是Service。 TIP 最新 Kubernetes 版本里，推荐使用 Deployment Service如果Pods是短暂的，那么重启时IP地址可能会改变，怎么才能从前端容器正确可靠地指向后台容器呢？ [Service] 抽象 现在，假定有2个后台Pod，并且定义后台Service的名称为‘backend-service’，label选择器为(tier=backend, app=myapp) 的Service会完成如下两件重要的事情： 会为Service创建一个本地集群的DNS入口，因此前端Pod只需要DNS查找主机名为 ‘backend-service’，就能够解析出前端应用程序可用的IP地址。 现在前端已经得到了后台服务的IP地址，但是它应该访问2个后台Pod的哪一个呢？Service在这2个后台Pod之间提供透明的负载均衡，会将请求分发给其中的任意一个（如下面的动画所示）。通过每个Node上运行的代理（kube-proxy）完成。 下述动画展示了Service的功能。注意该图作了很多简化。如果不进入网络配置，那么达到透明的负载均衡目标所涉及的底层网络和路由相对先进。如果有兴趣，有更深入的介绍。 每个节点都运行如下Kubernetes关键组件： Kubelet：是主节点代理。 Kube-proxy：Service使用其将链接路由到Pod，如上文所述。 Docker或Rocket：Kubernetes使用的容器技术来创建容器。 Kubernetes Master集群拥有一个Kubernetes Master（紫色方框）。Kubernetes Master提供集群的独特视角，并且拥有一系列组件，比如Kubernetes API Server。API Server提供可以用来和集群交互的REST端点。master节点包括用来创建和复制Pod的Replication Controller。","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://yoursite.com/categories/kubernetes/"}],"tags":[]},{"title":"hexo 使用","slug":"hexo使用","date":"2020-03-19T09:18:36.000Z","updated":"2020-03-23T07:14:57.409Z","comments":true,"path":"2020/03/19/hexo使用/","link":"","permalink":"http://yoursite.com/2020/03/19/hexo%E4%BD%BF%E7%94%A8/","excerpt":"hexo 搭建、部署、操作；","text":"hexo 搭建、部署、操作； _config.yml配置git 1234deploy: type: &#39;git&#39; repo: git@github.com:yourname&#x2F;yourname.github.io.git branch: master 上传github，推送文件步骤：hexo clean hexo c 清除缓存文件 (db.json) 和已生成的静态文件 (public) hexo generate hexo g 生成静态文件 hexo deploy hexo d 部署网站 执行端口启动： 1hexo s -i 0.0.0.0 -p 8080 绑定个人域名： 解析域名注意，博客网址中必须使用你github的用户名. 布局（Layout） Hexo 有三种默认布局：post、page 和 draft。在创建者三种不同类型的文件时，它们将会被保存到不同的路径；而您自定义的其他布局和 post 相同，都将储存到 source/_posts 文件夹。 布局 路径 post source/_posts page source draft source/_drafts hexo init 1hexo init [ folder] 新建一个网站。如果没有设置 folder ，Hexo 默认在目前的文件夹建立网站。 hexo new 1hexo new [layout] &lt;title&gt; 新建一篇文章。如果没有设置 layout 的话，默认使用 _config.yml 中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。 hexo new “post title with whitespace” 参数 描述 -p, –path 自定义新文章的路径 -r, –replace 如果存在同名文章，将其替换 -s, –slug 文章的 Slug，作为新文章的文件名和发布后的 URL 默认情况下，Hexo 会使用文章的标题来决定文章文件的路径。对于独立页面来说，Hexo 会创建一个以标题为名字的目录，并在目录中放置一个 index.md 文件。你可以使用 –path 参数来覆盖上述行为、自行决定文件的目录： 1hexo new page --path about&#x2F;me &quot;About me&quot; 以上命令会创建一个 source/about/me.md 文件，同时 Front Matter 中的 title 为 “About me” 注意！title 是必须指定的！如果你这么做并不能达到你的目的： 1hexo new page --path about&#x2F;me 此时 Hexo 会创建 source/_posts/about/me.md，同时 me.md 的 Front Matter 中的 title 为 “page”。这是因为在上述命令中，hexo-cli 将 page 视为指定文章的标题、并采用默认的 layout。","categories":[{"name":"工具","slug":"工具","permalink":"http://yoursite.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[]}]}